# -*- coding: utf-8 -*-
"""Machine_Learning_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FZ1iioiTpLhSZ5AzkoJR9gE6ONJatlvi
"""

#The code for this project was all written in python language. Using various SVM models we were able to create a code that imports data around Diabetes occurence.
#The code in this section uploads the file. Ensure you have the file downloaded unto your computer.
#Each cell in this project file contains a separate unit that must be run in sequence before the next unit is run. This ensures that all of the code runs smoothly. 
#If there is an issue running the code, ensure all the previous models run correctly.
from google.colab import files
uploaded=files.upload()

#The following python modules are necessary for operating and running the code.
import csv
import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn import preprocessing
from sklearn import linear_model
from sklearn.linear_model import LogisticRegressionCV, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn import svm
import matplotlib.pyplot as plt
from sklearn.linear_model import LassoCV, LassoLarsCV
from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix,auc, accuracy_score
from sklearn.metrics import classification_report

#Import the data from the file into a variable for manipulation
csvf =csv.reader(open('Diabetes Group Project Data.csv','r'))


#Standardize the data
df = pd.read_csv(r'Diabetes Group Project Data.csv')

#Replace missing values with the column average
mean_Glucose = df['Glucose'].mean()
df = df.replace({'Glucose': {0:mean_Glucose}})

mean_BloodPressure = df['BloodPressure'].mean()
df = df.replace({'BloodPressure': {0:mean_BloodPressure}})

mean_SkinThickness = df['SkinThickness'].mean()
df = df.replace({'SkinThickness': {0:mean_SkinThickness}})

mean_Insulin = df['Insulin'].mean()
df = df.replace({'Insulin': {0:mean_Insulin}})

mean_BMI = df['BMI'].mean()
df = df.replace({'BMI': {0:mean_BMI}})

mean_Age = df['Age'].mean()
df = df.replace({'Age': {0:mean_Age}})


df['Pregnancies'] = preprocessing.scale(df['Pregnancies'])
df ['Glucose'] = preprocessing.scale(df['Glucose'])
df['BloodPressure']= preprocessing.scale(df['BloodPressure'])
df['SkinThickness'] = preprocessing.scale (df['SkinThickness'])
df['Insulin'] = preprocessing.scale (df['Insulin'])
df['BMI'] = preprocessing.scale (df['BMI'])
df['Age'] = preprocessing.scale (df['Age'])

#Add the data to the necessary variables for manipulation.

Y = df['Outcome']

df = df.drop(['Outcome'],axis=1)

X = pd.concat([df],axis=1)


print (X.shape, Y.shape) 

df.head()

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.4, random_state = 1234)

#SVM Linear model

alf = svm.SVC (kernel = 'linear', C=1000, probability = True)
alf.fit(X_train,Y_train)

print(alf.n_support_) #number of support vectors for this model

func = alf.predict(X_test)
#print(func)
g = alf.decision_function(X_test)
#print(g)


       

allresults = alf.predict_proba(X_test)

scores = classification_report(Y_test,func)

print(scores)

#RBF Models to find best model

blf = svm.SVC (kernel = 'rbf', C=0.01, gamma = 1, probability = True)
blf.fit(X_train,Y_train)

clf = svm.SVC (kernel = 'rbf', C=0.001, gamma = 1, probability = True )
clf.fit(X_train,Y_train)

dlf = svm.SVC (kernel = 'rbf', C=1.0, gamma = 1 ,probability = True )
dlf.fit(X_train,Y_train)

elf = svm.SVC (kernel = 'rbf', C=5.0, gamma = 1 , probability = True)
elf.fit(X_train,Y_train)

flf = svm.SVC (kernel = 'rbf', C=1.0, gamma = 0.005 ,probability = True )
flf.fit(X_train,Y_train)

glf = svm.SVC (kernel = 'rbf', C=1.0, gamma = 0.05, probability = True )
glf.fit(X_train,Y_train)

hlf = svm.SVC (kernel = 'rbf', C=1.0, gamma = 0.5, probability = True )
hlf.fit(X_train,Y_train)

ilf = svm.SVC (kernel = 'rbf', C=1.0, gamma = 3, probability = True )
ilf.fit(X_train,Y_train)



bfunc = blf.predict(X_test)
bscores = classification_report(Y_test,bfunc)
print(bscores)


cfunc = clf.predict(X_test)
cscores = classification_report(Y_test,cfunc)
print(cscores)

dfunc = dlf.predict(X_test)
dscores = classification_report(Y_test,dfunc)
print(dscores)

efunc = elf.predict(X_test)
escores = classification_report(Y_test,efunc)
print(escores)

ffunc = flf.predict(X_test)
fscores = classification_report(Y_test,ffunc)
print(fscores)

gfunc = glf.predict(X_test)
gscores = classification_report(Y_test,gfunc)
print(gscores)

hfunc = hlf.predict(X_test)
hscores = classification_report(Y_test,hfunc)
print(hscores)

ifunc = ilf.predict(X_test)
iscores = classification_report(Y_test,ifunc)
print(iscores)

fpr_0, tpr_0,_ = roc_curve(Y_test, allresults[:,0], pos_label=0)
roc_auc_0= roc_auc_score(Y_test, 1 - allresults[:,0])

fpr_1,tpr_1,_ = roc_curve(Y_test, allresults[:,1], pos_label=1)
roc_auc_1 = roc_auc_score(Y_test, allresults[:,1])

print ('roc_auc_0: ', roc_auc_0)
print ('roc_auc_1:' , roc_auc_1, '\n')

plt.plot(fpr_0, tpr_0, marker = '.', label= "Class 0", color ='b')
plt.plot(fpr_1, tpr_1, marker ='.', label ='Class 1', color = 'r')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

#Using best RBF model

rfbest = svm.SVC (kernel = 'rbf', C=2.0, gamma = 0.5, probability = True )
rfbest.fit(X_train,Y_train)

bestfunc = rfbest.predict(X_test)
bestscores = classification_report(Y_test,bestfunc)
print(bestscores)

print ("Number of support vectors in each class for rbf model is", rfbest.n_support_)

# ROC curve

probab = rfbest.predict_proba(X_test)

fpr_0, tpr_0,_ = roc_curve(Y_test, probab[:,0], pos_label=0)
roc_auc_0= roc_auc_score(Y_test, 1 - probab[:,0])

fpr_1,tpr_1,_ = roc_curve(Y_test, probab[:,1], pos_label=1)
roc_auc_1 = roc_auc_score(Y_test, probab[:,1])

print ('roc_auc_0: ', roc_auc_0)
print ('roc_auc_1:' , roc_auc_1, '\n')

plt.plot(fpr_0, tpr_0, marker = '.', label= "Class 0", color ='b')
plt.plot(fpr_1, tpr_1, marker ='.', label ='Class 1', color = 'r')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

from sklearn.svm import SVC
alf.fit(X_test, Y_test) 
print('w = ',alf.coef_)
print('b = ',alf.intercept_)
#print('Indices of support vectors = ', alf.support_)
print('Support vectors = ', alf.support_vectors_)
#print('Number of support vectors for each class = ', alf.n_support_)
#print('Coefficients of the support vector in the decision function = ', np.abs(alf.dual_coef_))

def plot_svc_decision_function(alf, ax=None, plot_support=True):
    """Plot the decision function for a 2D SVC"""
    if ax is None:
        ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()
    
    # create grid to evaluate model
    x = np.linspace(xlim[0], xlim[1], 30)
    y = np.linspace(ylim[0], ylim[1], 30)
    Y, X = np.meshgrid(y, x)
    xy = np.vstack([X.ravel(), Y.ravel()]).T
    P = alf.decision_function(xy).reshape(X.shape)
    
    # plot decision boundary and margins
    ax.contour(X, Y, P, colors='k',
               levels=[-1, 0, 1], alpha=0.5,
               linestyles=['--', '-', '--'])
    
    # plot support vectors
    if plot_support:
        ax.scatter(alf.support_vectors_[:, 0],
                   alf.support_vectors_[:, 1],
                   s=300, linewidth=1, facecolors='none');
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)

# from sklearn.svm import SVC
# import numpy as np
# import matplotlib.pyplot as plt
# from sklearn import svm, datasets

# alf = svm.SVC (kernel = 'linear', C=1000, probability = True)
# alf.fit(X,Y)

# def make_meshgrid(x, y, h=.02):
#     x_min, x_max = x.min() - 1, x.max() + 1
#     y_min, y_max = y.min() - 1, y.max() + 1
#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
#     return xx, yy

# def plot_contours(ax, clf, xx, yy, **params):
#     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
#     Z = Z.reshape(xx.shape)
#     out = ax.contourf(xx, yy, Z, **params)
#     return out

# model = svm.SVC(kernel='linear', C=1000, probability = True)
# clf = model.fit(X, Y)

# fig, ax = plt.subplots()
# # title for the plots
# title = ('Decision surface of linear SVC ')
# # Set-up grid for plotting.


# #trying to convert df into an array to graph
# X = df.iloc[:,:-1].values
# Y = df.iloc[:,-1].values


# X0, X1 = X[:, 0], X[:, 1]
# xx, yy = make_meshgrid(X0, X1)

# plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
# ax.scatter(X0, X1, c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')
# ax.set_ylabel('y label here')
# ax.set_xlabel('x label here')
# ax.set_xticks(())
# ax.set_yticks(())
# ax.set_title(title)
# ax.legend()
# plt.show()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean',verbose=0)
imputer = imputer.fit(X.iloc[:, 1:3])
X.iloc[:, 1:3] = imputer.transform(X.iloc[:, 1:3])